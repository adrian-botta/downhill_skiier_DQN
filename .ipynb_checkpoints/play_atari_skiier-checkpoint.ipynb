{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2-yoda/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from skiier import *\n",
    "from ski_env import *\n",
    "from rl_logger import rl_metrics_logger\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import papermill as pm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2-yoda/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "repeat_freq = 4\n",
    "ski_env = gym.make(\"Skiing-v0\")\n",
    "ski_env_w = Env_wrapper(ski_env, repeat_freq)\n",
    "skiier = Skiier(action_space = 3, LEARNING_RATE = 0.0001, LAMBDA = 0.075, GAMMA = 0.99, \n",
    "                MEMORY_CAPACITY = 10000, BATCH_SIZE = 1000, max_explore_game = 300, \n",
    "                repeat_freq = repeat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1000, frames: 2264, epsilon: 1, reward: -35.0\n",
      "model_loss: 0, frames_seen: 2264, memory_level: 567\n",
      "episode: 1/1000, frames: 1820, epsilon: 1, reward: -35.0\n",
      "model_loss: 0, frames_seen: 4084, memory_level: 1023\n",
      "episode: 2/1000, frames: 1460, epsilon: 1, reward: -44.0\n",
      "model_loss: 0, frames_seen: 5544, memory_level: 1389\n",
      "episode: 3/1000, frames: 2104, epsilon: 1, reward: -35.0\n",
      "model_loss: 0, frames_seen: 7648, memory_level: 1916\n",
      "episode: 4/1000, frames: 1472, epsilon: 1, reward: -40.0\n",
      "model_loss: 0, frames_seen: 9120, memory_level: 2285\n",
      "episode: 5/1000, frames: 1720, epsilon: 1, reward: -39.0\n",
      "model_loss: 0, frames_seen: 10840, memory_level: 2716\n",
      "episode: 6/1000, frames: 1844, epsilon: 1, reward: -39.0\n",
      "model_loss: 0, frames_seen: 12684, memory_level: 3178\n",
      "episode: 7/1000, frames: 1972, epsilon: 1, reward: -34.0\n",
      "model_loss: 0, frames_seen: 14656, memory_level: 3672\n",
      "episode: 8/1000, frames: 1952, epsilon: 1, reward: -38.0\n",
      "model_loss: 0, frames_seen: 16608, memory_level: 4161\n",
      "episode: 9/1000, frames: 1952, epsilon: 1, reward: -35.0\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "model_loss: 17.544727325439453, frames_seen: 18560, memory_level: 4650\n",
      "episode: 10/1000, frames: 1616, epsilon: 0.9703, reward: -40.0\n",
      "model_loss: 20.985593795776367, frames_seen: 20176, memory_level: 5055\n",
      "episode: 11/1000, frames: 1760, epsilon: 0.967, reward: -38.0\n",
      "model_loss: 14.117300033569336, frames_seen: 21936, memory_level: 5496\n",
      "episode: 12/1000, frames: 1968, epsilon: 0.9637, reward: -36.0\n",
      "model_loss: 10.564949035644531, frames_seen: 23904, memory_level: 5989\n",
      "episode: 13/1000, frames: 2040, epsilon: 0.9604, reward: -36.0\n",
      "model_loss: 9.536471366882324, frames_seen: 25944, memory_level: 6500\n",
      "episode: 14/1000, frames: 2068, epsilon: 0.9571, reward: -37.0\n",
      "model_loss: 9.851338386535645, frames_seen: 28012, memory_level: 7018\n",
      "episode: 15/1000, frames: 1656, epsilon: 0.9538, reward: -43.0\n",
      "model_loss: 17.37006950378418, frames_seen: 29668, memory_level: 7433\n",
      "episode: 16/1000, frames: 1936, epsilon: 0.9505, reward: -39.0\n",
      "model_loss: 22.77428436279297, frames_seen: 31604, memory_level: 7918\n",
      "episode: 17/1000, frames: 1616, epsilon: 0.9472, reward: -39.0\n",
      "model_loss: 10.055817604064941, frames_seen: 33220, memory_level: 8323\n",
      "episode: 18/1000, frames: 2124, epsilon: 0.9439, reward: -38.0\n",
      "model_loss: 17.17857551574707, frames_seen: 35344, memory_level: 8855\n",
      "episode: 19/1000, frames: 1724, epsilon: 0.9406, reward: -35.0\n",
      "model_loss: 17.42668342590332, frames_seen: 37068, memory_level: 9287\n",
      "episode: 20/1000, frames: 1932, epsilon: 0.9373, reward: -31.0\n",
      "model_loss: 12.861074447631836, frames_seen: 39000, memory_level: 9771\n",
      "episode: 21/1000, frames: 2092, epsilon: 0.9339999999999999, reward: -34.0\n",
      "model_loss: 6.326723098754883, frames_seen: 41092, memory_level: 10000\n",
      "episode: 22/1000, frames: 1596, epsilon: 0.9307, reward: -41.0\n",
      "model_loss: 6.282148838043213, frames_seen: 42688, memory_level: 10000\n",
      "episode: 23/1000, frames: 1724, epsilon: 0.9274, reward: -40.0\n",
      "model_loss: 10.380695343017578, frames_seen: 44412, memory_level: 10000\n",
      "episode: 24/1000, frames: 2076, epsilon: 0.9241, reward: -38.0\n",
      "model_loss: 18.79918098449707, frames_seen: 46488, memory_level: 10000\n",
      "episode: 25/1000, frames: 1476, epsilon: 0.9208000000000001, reward: -42.0\n",
      "model_loss: 6.29337739944458, frames_seen: 47964, memory_level: 10000\n",
      "episode: 26/1000, frames: 2124, epsilon: 0.9175, reward: -38.0\n",
      "model_loss: 6.263479709625244, frames_seen: 50088, memory_level: 10000\n",
      "episode: 27/1000, frames: 2440, epsilon: 0.9142, reward: -36.0\n",
      "model_loss: 10.811972618103027, frames_seen: 52528, memory_level: 10000\n",
      "episode: 28/1000, frames: 1852, epsilon: 0.9109, reward: -38.0\n",
      "model_loss: 13.903958320617676, frames_seen: 54380, memory_level: 10000\n",
      "episode: 29/1000, frames: 2020, epsilon: 0.9076, reward: -39.0\n",
      "model_loss: 6.291144847869873, frames_seen: 56400, memory_level: 10000\n",
      "episode: 30/1000, frames: 1676, epsilon: 0.9043, reward: -40.0\n",
      "model_loss: 10.494195938110352, frames_seen: 58076, memory_level: 10000\n",
      "episode: 31/1000, frames: 2544, epsilon: 0.901, reward: -32.0\n",
      "model_loss: 13.560344696044922, frames_seen: 60620, memory_level: 10000\n",
      "episode: 32/1000, frames: 1536, epsilon: 0.8976999999999999, reward: -42.0\n",
      "model_loss: 10.304328918457031, frames_seen: 62156, memory_level: 10000\n",
      "episode: 33/1000, frames: 1544, epsilon: 0.8944, reward: -38.0\n",
      "model_loss: 14.033224105834961, frames_seen: 63700, memory_level: 10000\n",
      "episode: 34/1000, frames: 2588, epsilon: 0.8911, reward: -33.0\n",
      "model_loss: 10.288433074951172, frames_seen: 66288, memory_level: 10000\n",
      "episode: 35/1000, frames: 2464, epsilon: 0.8878, reward: -32.0\n",
      "model_loss: 14.359314918518066, frames_seen: 68752, memory_level: 10000\n",
      "episode: 36/1000, frames: 1768, epsilon: 0.8845, reward: -39.0\n",
      "model_loss: 9.310957908630371, frames_seen: 70520, memory_level: 10000\n",
      "episode: 37/1000, frames: 1604, epsilon: 0.8812, reward: -41.0\n",
      "model_loss: 14.559398651123047, frames_seen: 72124, memory_level: 10000\n",
      "episode: 38/1000, frames: 2116, epsilon: 0.8779, reward: -39.0\n",
      "model_loss: 10.763068199157715, frames_seen: 74240, memory_level: 10000\n",
      "episode: 39/1000, frames: 2776, epsilon: 0.8746, reward: -33.0\n",
      "model_loss: 13.383261680603027, frames_seen: 77016, memory_level: 10000\n",
      "episode: 40/1000, frames: 1756, epsilon: 0.8713, reward: -42.0\n",
      "model_loss: 10.365342140197754, frames_seen: 78772, memory_level: 10000\n",
      "episode: 41/1000, frames: 2628, epsilon: 0.868, reward: -32.0\n",
      "model_loss: 10.362566947937012, frames_seen: 81400, memory_level: 10000\n",
      "episode: 42/1000, frames: 2128, epsilon: 0.8647, reward: -38.0\n",
      "model_loss: 9.799864768981934, frames_seen: 83528, memory_level: 10000\n",
      "episode: 43/1000, frames: 3252, epsilon: 0.8613999999999999, reward: -32.0\n",
      "model_loss: 6.26564359664917, frames_seen: 86780, memory_level: 10000\n",
      "episode: 44/1000, frames: 2016, epsilon: 0.8581, reward: -36.0\n",
      "model_loss: 14.546072006225586, frames_seen: 88796, memory_level: 10000\n",
      "episode: 45/1000, frames: 2292, epsilon: 0.8548, reward: -35.0\n",
      "model_loss: 6.296352863311768, frames_seen: 91088, memory_level: 10000\n",
      "episode: 46/1000, frames: 2304, epsilon: 0.8515, reward: -38.0\n",
      "model_loss: 14.495950698852539, frames_seen: 93392, memory_level: 10000\n",
      "episode: 47/1000, frames: 2360, epsilon: 0.8482000000000001, reward: -36.0\n",
      "model_loss: 10.070426940917969, frames_seen: 95752, memory_level: 10000\n",
      "episode: 48/1000, frames: 2784, epsilon: 0.8449, reward: -31.0\n",
      "model_loss: 6.303184509277344, frames_seen: 98536, memory_level: 10000\n",
      "episode: 49/1000, frames: 2592, epsilon: 0.8416, reward: -34.0\n",
      "model_loss: 21.65361213684082, frames_seen: 101128, memory_level: 10000\n",
      "episode: 50/1000, frames: 2968, epsilon: 0.8383, reward: -33.0\n",
      "model_loss: 11.055209159851074, frames_seen: 104096, memory_level: 10000\n",
      "episode: 51/1000, frames: 2208, epsilon: 0.835, reward: -37.0\n",
      "model_loss: 10.327936172485352, frames_seen: 106304, memory_level: 10000\n",
      "episode: 52/1000, frames: 2928, epsilon: 0.8317, reward: -33.0\n",
      "model_loss: 10.817249298095703, frames_seen: 109232, memory_level: 10000\n",
      "episode: 53/1000, frames: 3032, epsilon: 0.8284, reward: -32.0\n",
      "model_loss: 10.119263648986816, frames_seen: 112264, memory_level: 10000\n",
      "episode: 54/1000, frames: 3304, epsilon: 0.8251, reward: -31.0\n",
      "model_loss: 10.808793067932129, frames_seen: 115568, memory_level: 10000\n",
      "episode: 55/1000, frames: 3244, epsilon: 0.8218, reward: -31.0\n",
      "model_loss: 15.321572303771973, frames_seen: 118812, memory_level: 10000\n",
      "episode: 56/1000, frames: 2536, epsilon: 0.8185, reward: -35.0\n",
      "model_loss: 13.840038299560547, frames_seen: 121348, memory_level: 10000\n",
      "episode: 57/1000, frames: 2980, epsilon: 0.8152, reward: -33.0\n",
      "model_loss: 9.830574035644531, frames_seen: 124328, memory_level: 10000\n",
      "episode: 58/1000, frames: 2180, epsilon: 0.8119000000000001, reward: -32.0\n",
      "model_loss: 14.110128402709961, frames_seen: 126508, memory_level: 10000\n",
      "episode: 59/1000, frames: 3384, epsilon: 0.8086, reward: -31.0\n",
      "model_loss: 6.315156936645508, frames_seen: 129892, memory_level: 10000\n",
      "episode: 60/1000, frames: 3056, epsilon: 0.8053, reward: -33.0\n",
      "model_loss: 6.308595657348633, frames_seen: 132948, memory_level: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 61/1000, frames: 2756, epsilon: 0.802, reward: -32.0\n",
      "model_loss: 10.525040626525879, frames_seen: 135704, memory_level: 10000\n",
      "episode: 62/1000, frames: 2588, epsilon: 0.7987, reward: -35.0\n",
      "model_loss: 15.580570220947266, frames_seen: 138292, memory_level: 10000\n",
      "episode: 63/1000, frames: 2068, epsilon: 0.7954, reward: -40.0\n",
      "model_loss: 15.060684204101562, frames_seen: 140360, memory_level: 10000\n",
      "episode: 64/1000, frames: 2920, epsilon: 0.7921, reward: -34.0\n",
      "model_loss: 15.332529067993164, frames_seen: 143280, memory_level: 10000\n",
      "episode: 65/1000, frames: 3332, epsilon: 0.7888, reward: -32.0\n",
      "model_loss: 6.279577732086182, frames_seen: 146612, memory_level: 10000\n",
      "episode: 66/1000, frames: 2516, epsilon: 0.7855, reward: -34.0\n",
      "model_loss: 11.060688018798828, frames_seen: 149128, memory_level: 10000\n",
      "episode: 67/1000, frames: 2408, epsilon: 0.7822, reward: -36.0\n",
      "model_loss: 6.289994716644287, frames_seen: 151536, memory_level: 10000\n",
      "episode: 68/1000, frames: 2460, epsilon: 0.7789, reward: -36.0\n",
      "model_loss: 11.477420806884766, frames_seen: 153996, memory_level: 10000\n",
      "episode: 69/1000, frames: 3340, epsilon: 0.7756000000000001, reward: -31.0\n",
      "model_loss: 6.418309211730957, frames_seen: 157336, memory_level: 10000\n",
      "episode: 70/1000, frames: 2980, epsilon: 0.7723, reward: -33.0\n",
      "model_loss: 13.669988632202148, frames_seen: 160316, memory_level: 10000\n",
      "episode: 71/1000, frames: 3048, epsilon: 0.769, reward: -33.0\n",
      "model_loss: 11.012662887573242, frames_seen: 163364, memory_level: 10000\n",
      "episode: 72/1000, frames: 3964, epsilon: 0.7657, reward: -30.0\n",
      "model_loss: 15.295124053955078, frames_seen: 167328, memory_level: 10000\n",
      "episode: 73/1000, frames: 3056, epsilon: 0.7624, reward: -32.0\n",
      "model_loss: 11.753192901611328, frames_seen: 170384, memory_level: 10000\n",
      "episode: 74/1000, frames: 4620, epsilon: 0.7591, reward: -29.0\n",
      "model_loss: 10.789854049682617, frames_seen: 175004, memory_level: 10000\n",
      "episode: 75/1000, frames: 3440, epsilon: 0.7558, reward: -32.0\n",
      "model_loss: 6.39889669418335, frames_seen: 178444, memory_level: 10000\n",
      "episode: 76/1000, frames: 4716, epsilon: 0.7525, reward: -28.0\n",
      "model_loss: 6.357499599456787, frames_seen: 183160, memory_level: 10000\n",
      "episode: 77/1000, frames: 3804, epsilon: 0.7492, reward: -30.0\n",
      "model_loss: 6.342483997344971, frames_seen: 186964, memory_level: 10000\n",
      "episode: 78/1000, frames: 2552, epsilon: 0.7459, reward: -36.0\n",
      "model_loss: 6.369134902954102, frames_seen: 189516, memory_level: 10000\n",
      "episode: 79/1000, frames: 3248, epsilon: 0.7425999999999999, reward: -31.0\n",
      "model_loss: 6.306431770324707, frames_seen: 192764, memory_level: 10000\n",
      "episode: 80/1000, frames: 4652, epsilon: 0.7393000000000001, reward: -29.0\n",
      "model_loss: 6.323071002960205, frames_seen: 197416, memory_level: 10000\n",
      "episode: 81/1000, frames: 4416, epsilon: 0.736, reward: -29.0\n",
      "model_loss: 11.027881622314453, frames_seen: 201832, memory_level: 10000\n",
      "episode: 82/1000, frames: 3496, epsilon: 0.7327, reward: -31.0\n",
      "model_loss: 6.334434509277344, frames_seen: 205328, memory_level: 10000\n",
      "episode: 83/1000, frames: 3632, epsilon: 0.7294, reward: -30.0\n",
      "model_loss: 6.3175249099731445, frames_seen: 208960, memory_level: 10000\n",
      "episode: 84/1000, frames: 5100, epsilon: 0.7261, reward: -28.0\n",
      "model_loss: 6.308866500854492, frames_seen: 214060, memory_level: 10000\n",
      "episode: 85/1000, frames: 4716, epsilon: 0.7228, reward: -28.0\n",
      "model_loss: 6.299803256988525, frames_seen: 218776, memory_level: 10000\n",
      "episode: 86/1000, frames: 4420, epsilon: 0.7195, reward: -29.0\n",
      "model_loss: 6.282621383666992, frames_seen: 223196, memory_level: 10000\n",
      "episode: 87/1000, frames: 2744, epsilon: 0.7162, reward: -34.0\n",
      "model_loss: 10.798783302307129, frames_seen: 225940, memory_level: 10000\n",
      "episode: 88/1000, frames: 3536, epsilon: 0.7129, reward: -31.0\n",
      "model_loss: 15.357085227966309, frames_seen: 229476, memory_level: 10000\n",
      "episode: 89/1000, frames: 4432, epsilon: 0.7096, reward: -27.0\n",
      "model_loss: 11.095250129699707, frames_seen: 233908, memory_level: 10000\n",
      "episode: 90/1000, frames: 3948, epsilon: 0.7062999999999999, reward: -30.0\n",
      "model_loss: 6.331526279449463, frames_seen: 237856, memory_level: 10000\n",
      "episode: 91/1000, frames: 5792, epsilon: 0.7030000000000001, reward: -27.0\n",
      "model_loss: 6.286206245422363, frames_seen: 243648, memory_level: 10000\n",
      "episode: 92/1000, frames: 4656, epsilon: 0.6997, reward: -28.0\n",
      "model_loss: 6.362031936645508, frames_seen: 248304, memory_level: 10000\n",
      "episode: 93/1000, frames: 4568, epsilon: 0.6964, reward: -27.0\n",
      "model_loss: 6.359868049621582, frames_seen: 252872, memory_level: 10000\n",
      "episode: 94/1000, frames: 6044, epsilon: 0.6931, reward: -20.0\n",
      "model_loss: 10.875283241271973, frames_seen: 258916, memory_level: 10000\n",
      "episode: 95/1000, frames: 3868, epsilon: 0.6898, reward: -30.0\n",
      "model_loss: 11.056899070739746, frames_seen: 262784, memory_level: 10000\n",
      "episode: 96/1000, frames: 5980, epsilon: 0.6865, reward: -20.0\n",
      "model_loss: 6.3155622482299805, frames_seen: 268764, memory_level: 10000\n",
      "episode: 97/1000, frames: 4748, epsilon: 0.6832, reward: -28.0\n",
      "model_loss: 6.285390853881836, frames_seen: 273512, memory_level: 10000\n",
      "episode: 98/1000, frames: 5004, epsilon: 0.6799, reward: -28.0\n",
      "model_loss: 6.274026870727539, frames_seen: 278516, memory_level: 10000\n",
      "episode: 99/1000, frames: 4464, epsilon: 0.6766, reward: -29.0\n",
      "model_loss: 10.99203109741211, frames_seen: 282980, memory_level: 10000\n",
      "episode: 100/1000, frames: 5044, epsilon: 0.6733, reward: -28.0\n",
      "model_loss: 11.116829872131348, frames_seen: 288024, memory_level: 10000\n",
      "episode: 101/1000, frames: 4724, epsilon: 0.6699999999999999, reward: -29.0\n",
      "model_loss: 16.44603157043457, frames_seen: 292748, memory_level: 10000\n",
      "episode: 102/1000, frames: 5924, epsilon: 0.6667000000000001, reward: -26.0\n",
      "model_loss: 6.290739059448242, frames_seen: 298672, memory_level: 10000\n",
      "episode: 103/1000, frames: 5908, epsilon: 0.6634, reward: -27.0\n",
      "model_loss: 10.863104820251465, frames_seen: 304580, memory_level: 10000\n",
      "episode: 104/1000, frames: 5988, epsilon: 0.6601, reward: -20.0\n",
      "model_loss: 6.312045574188232, frames_seen: 310568, memory_level: 10000\n",
      "episode: 105/1000, frames: 4004, epsilon: 0.6568, reward: -30.0\n",
      "model_loss: 6.333208084106445, frames_seen: 314572, memory_level: 10000\n",
      "episode: 106/1000, frames: 5348, epsilon: 0.6535, reward: -28.0\n",
      "model_loss: 20.526649475097656, frames_seen: 319920, memory_level: 10000\n",
      "episode: 107/1000, frames: 6004, epsilon: 0.6502, reward: -20.0\n",
      "model_loss: 6.362911701202393, frames_seen: 325924, memory_level: 10000\n",
      "episode: 108/1000, frames: 5968, epsilon: 0.6469, reward: -20.0\n",
      "model_loss: 6.402413845062256, frames_seen: 331892, memory_level: 10000\n",
      "episode: 109/1000, frames: 6008, epsilon: 0.6436, reward: -20.0\n",
      "model_loss: 6.388610363006592, frames_seen: 337900, memory_level: 10000\n",
      "episode: 110/1000, frames: 5340, epsilon: 0.6403, reward: -27.0\n",
      "model_loss: 6.381507873535156, frames_seen: 343240, memory_level: 10000\n",
      "episode: 111/1000, frames: 5996, epsilon: 0.637, reward: -20.0\n",
      "model_loss: 11.028220176696777, frames_seen: 349236, memory_level: 10000\n",
      "episode: 112/1000, frames: 5424, epsilon: 0.6336999999999999, reward: -27.0\n",
      "model_loss: 6.390712261199951, frames_seen: 354660, memory_level: 10000\n",
      "episode: 113/1000, frames: 6000, epsilon: 0.6304000000000001, reward: -20.0\n",
      "model_loss: 6.326516628265381, frames_seen: 360660, memory_level: 10000\n",
      "episode: 114/1000, frames: 6008, epsilon: 0.6271, reward: -20.0\n",
      "model_loss: 6.33544921875, frames_seen: 366668, memory_level: 10000\n",
      "episode: 115/1000, frames: 6008, epsilon: 0.6238, reward: -20.0\n",
      "model_loss: 6.390305995941162, frames_seen: 372676, memory_level: 10000\n",
      "episode: 116/1000, frames: 5992, epsilon: 0.6205, reward: -20.0\n",
      "model_loss: 6.362371444702148, frames_seen: 378668, memory_level: 10000\n",
      "episode: 117/1000, frames: 6040, epsilon: 0.6172, reward: -20.0\n",
      "model_loss: 6.340860366821289, frames_seen: 384708, memory_level: 10000\n",
      "episode: 118/1000, frames: 6004, epsilon: 0.6139, reward: -20.0\n",
      "model_loss: 11.102348327636719, frames_seen: 390712, memory_level: 10000\n",
      "episode: 119/1000, frames: 6000, epsilon: 0.6106, reward: -20.0\n",
      "model_loss: 6.378738880157471, frames_seen: 396712, memory_level: 10000\n",
      "episode: 120/1000, frames: 6016, epsilon: 0.6073, reward: -20.0\n",
      "model_loss: 6.382725238800049, frames_seen: 402728, memory_level: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 121/1000, frames: 6020, epsilon: 0.604, reward: -20.0\n",
      "model_loss: 6.372037887573242, frames_seen: 408748, memory_level: 10000\n",
      "episode: 122/1000, frames: 5848, epsilon: 0.6007, reward: -27.0\n",
      "model_loss: 6.281805515289307, frames_seen: 414596, memory_level: 10000\n",
      "episode: 123/1000, frames: 6028, epsilon: 0.5973999999999999, reward: -20.0\n",
      "model_loss: 6.339372634887695, frames_seen: 420624, memory_level: 10000\n",
      "episode: 124/1000, frames: 5996, epsilon: 0.5941000000000001, reward: -20.0\n",
      "model_loss: 6.378062725067139, frames_seen: 426620, memory_level: 10000\n",
      "episode: 125/1000, frames: 6012, epsilon: 0.5908, reward: -20.0\n",
      "model_loss: 11.081853866577148, frames_seen: 432632, memory_level: 10000\n",
      "episode: 126/1000, frames: 6024, epsilon: 0.5875, reward: -20.0\n",
      "model_loss: 6.404573440551758, frames_seen: 438656, memory_level: 10000\n",
      "episode: 127/1000, frames: 5984, epsilon: 0.5842, reward: -20.0\n",
      "model_loss: 6.325231552124023, frames_seen: 444640, memory_level: 10000\n",
      "episode: 128/1000, frames: 6016, epsilon: 0.5809, reward: -20.0\n",
      "model_loss: 6.351615905761719, frames_seen: 450656, memory_level: 10000\n",
      "episode: 129/1000, frames: 6008, epsilon: 0.5776, reward: -20.0\n",
      "model_loss: 6.353847026824951, frames_seen: 456664, memory_level: 10000\n",
      "episode: 130/1000, frames: 6024, epsilon: 0.5743, reward: -20.0\n",
      "model_loss: 6.4122209548950195, frames_seen: 462688, memory_level: 10000\n",
      "episode: 131/1000, frames: 6000, epsilon: 0.571, reward: -20.0\n",
      "model_loss: 6.345451354980469, frames_seen: 468688, memory_level: 10000\n",
      "episode: 132/1000, frames: 6036, epsilon: 0.5677, reward: -20.0\n",
      "model_loss: 6.381445407867432, frames_seen: 474724, memory_level: 10000\n",
      "episode: 133/1000, frames: 5980, epsilon: 0.5644, reward: -20.0\n",
      "model_loss: 6.392673015594482, frames_seen: 480704, memory_level: 10000\n",
      "episode: 134/1000, frames: 5992, epsilon: 0.5610999999999999, reward: -20.0\n",
      "model_loss: 6.347421646118164, frames_seen: 486696, memory_level: 10000\n",
      "episode: 135/1000, frames: 6016, epsilon: 0.5578000000000001, reward: -20.0\n",
      "model_loss: 6.310620307922363, frames_seen: 492712, memory_level: 10000\n",
      "episode: 136/1000, frames: 6016, epsilon: 0.5545, reward: -20.0\n",
      "model_loss: 6.331728935241699, frames_seen: 498728, memory_level: 10000\n",
      "episode: 137/1000, frames: 5988, epsilon: 0.5512, reward: -20.0\n",
      "model_loss: 6.341396808624268, frames_seen: 504716, memory_level: 10000\n",
      "episode: 138/1000, frames: 6028, epsilon: 0.5479, reward: -20.0\n",
      "model_loss: 6.3462724685668945, frames_seen: 510744, memory_level: 10000\n",
      "episode: 139/1000, frames: 6020, epsilon: 0.5446, reward: -20.0\n",
      "model_loss: 6.35093879699707, frames_seen: 516764, memory_level: 10000\n",
      "episode: 140/1000, frames: 6016, epsilon: 0.5413, reward: -20.0\n",
      "model_loss: 6.426015853881836, frames_seen: 522780, memory_level: 10000\n",
      "episode: 141/1000, frames: 6008, epsilon: 0.538, reward: -20.0\n",
      "model_loss: 6.270712375640869, frames_seen: 528788, memory_level: 10000\n",
      "episode: 142/1000, frames: 5984, epsilon: 0.5347, reward: -20.0\n",
      "model_loss: 6.3959879875183105, frames_seen: 534772, memory_level: 10000\n",
      "episode: 143/1000, frames: 6000, epsilon: 0.5314, reward: -20.0\n",
      "model_loss: 6.369670391082764, frames_seen: 540772, memory_level: 10000\n",
      "episode: 144/1000, frames: 6024, epsilon: 0.5281, reward: -20.0\n",
      "model_loss: 6.341875076293945, frames_seen: 546796, memory_level: 10000\n",
      "episode: 145/1000, frames: 6032, epsilon: 0.5247999999999999, reward: -20.0\n",
      "model_loss: 6.337815761566162, frames_seen: 552828, memory_level: 10000\n",
      "episode: 146/1000, frames: 6032, epsilon: 0.5215000000000001, reward: -20.0\n",
      "model_loss: 6.378130912780762, frames_seen: 558860, memory_level: 10000\n",
      "episode: 147/1000, frames: 5976, epsilon: 0.5182, reward: -20.0\n",
      "model_loss: 6.352421760559082, frames_seen: 564836, memory_level: 10000\n",
      "episode: 148/1000, frames: 5968, epsilon: 0.5149, reward: -20.0\n",
      "model_loss: 6.369134426116943, frames_seen: 570804, memory_level: 10000\n",
      "episode: 149/1000, frames: 5996, epsilon: 0.5116, reward: -20.0\n",
      "model_loss: 6.389619827270508, frames_seen: 576800, memory_level: 10000\n",
      "episode: 150/1000, frames: 6012, epsilon: 0.5083, reward: -20.0\n",
      "model_loss: 6.327057361602783, frames_seen: 582812, memory_level: 10000\n",
      "episode: 151/1000, frames: 6032, epsilon: 0.505, reward: -20.0\n",
      "model_loss: 6.366559028625488, frames_seen: 588844, memory_level: 10000\n",
      "episode: 152/1000, frames: 6008, epsilon: 0.5017, reward: -20.0\n",
      "model_loss: 6.432446002960205, frames_seen: 594852, memory_level: 10000\n",
      "episode: 153/1000, frames: 6024, epsilon: 0.49839999999999995, reward: -20.0\n",
      "model_loss: 6.365269184112549, frames_seen: 600876, memory_level: 10000\n",
      "episode: 154/1000, frames: 6024, epsilon: 0.4951, reward: -20.0\n",
      "model_loss: 6.409916877746582, frames_seen: 606900, memory_level: 10000\n",
      "episode: 155/1000, frames: 5992, epsilon: 0.4918, reward: -20.0\n",
      "model_loss: 6.36818265914917, frames_seen: 612892, memory_level: 10000\n",
      "episode: 156/1000, frames: 5992, epsilon: 0.48850000000000005, reward: -20.0\n",
      "model_loss: 6.396392822265625, frames_seen: 618884, memory_level: 10000\n",
      "episode: 157/1000, frames: 6008, epsilon: 0.48519999999999996, reward: -20.0\n",
      "model_loss: 6.405727863311768, frames_seen: 624892, memory_level: 10000\n",
      "episode: 158/1000, frames: 5996, epsilon: 0.4819, reward: -20.0\n",
      "model_loss: 6.352963447570801, frames_seen: 630888, memory_level: 10000\n",
      "episode: 159/1000, frames: 6000, epsilon: 0.4786, reward: -20.0\n",
      "model_loss: 6.364873886108398, frames_seen: 636888, memory_level: 10000\n",
      "episode: 160/1000, frames: 5996, epsilon: 0.47530000000000006, reward: -20.0\n",
      "model_loss: 6.4475250244140625, frames_seen: 642884, memory_level: 10000\n",
      "episode: 161/1000, frames: 6036, epsilon: 0.472, reward: -20.0\n",
      "model_loss: 6.364119052886963, frames_seen: 648920, memory_level: 10000\n",
      "episode: 162/1000, frames: 6044, epsilon: 0.4687, reward: -20.0\n",
      "model_loss: 6.390841960906982, frames_seen: 654964, memory_level: 10000\n",
      "episode: 163/1000, frames: 5996, epsilon: 0.46540000000000004, reward: -20.0\n",
      "model_loss: 6.357766628265381, frames_seen: 660960, memory_level: 10000\n",
      "episode: 164/1000, frames: 6004, epsilon: 0.46209999999999996, reward: -20.0\n",
      "model_loss: 6.349040508270264, frames_seen: 666964, memory_level: 10000\n",
      "episode: 165/1000, frames: 6016, epsilon: 0.4588, reward: -20.0\n",
      "model_loss: 6.362974643707275, frames_seen: 672980, memory_level: 10000\n",
      "episode: 166/1000, frames: 6012, epsilon: 0.4555, reward: -20.0\n",
      "model_loss: 6.419187545776367, frames_seen: 678992, memory_level: 10000\n"
     ]
    }
   ],
   "source": [
    "num_steps = 30000\n",
    "num_episodes = 1000\n",
    "logger = rl_metrics_logger()\n",
    "start_replay_episode = 10\n",
    "frames_seen = 0\n",
    "for episode in range(num_episodes):\n",
    "    state = ski_env_w.reset()\n",
    "    total_reward = 0\n",
    "    for time_step in range(num_steps):\n",
    "        action = skiier.act(state)\n",
    "        next_state, reward, done, info = ski_env_w.step(action)\n",
    "        skiier.observe(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        skiier.episode = episode\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, frames: {}, epsilon: {}, reward: {}\".format(episode, \n",
    "                                                                  num_episodes, \n",
    "                                                                  time_step*repeat_freq, \n",
    "                                                                  skiier.epsilon,\n",
    "                                                                  np.around(total_reward/time_step)))\n",
    "            break\n",
    "    \n",
    "    if episode+1 >= start_replay_episode:\n",
    "        skiier.replay()\n",
    "        model_loss = np.mean(skiier.brain.history.losses)\n",
    "    else:\n",
    "        model_loss = 0\n",
    "    #logging\n",
    "    frames_seen += time_step*repeat_freq\n",
    "    print(\"model_loss: {}, frames_seen: {}, memory_level: {}\".format(model_loss, \n",
    "                                                                     frames_seen, \n",
    "                                                                     skiier.memory.mem_size))\n",
    "    logger.store(episode, time_step*repeat_freq, skiier.epsilon, total_reward, model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Playing Game to Check Reward Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2-yoda/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "ski_env = gym.make(\"Skiing-v0\")\n",
    "ski_env_w = Env_wrapper(ski_env, 4)\n",
    "skiier = Skiier(action_space = 3, LEARNING_RATE = 0.0001, LAMBDA = 0.075, GAMMA = 0.99, \n",
    "                MEMORY_CAPACITY = 10000, BATCH_SIZE = 1000, max_explore_game = 300, \n",
    "                repeat_freq = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ski_env_w.reset()\n",
    "total_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f998e9c0cf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action = 2\n",
    "next_state, reward, done, info = ski_env_w.step(action)\n",
    "total_reward.append(reward)\n",
    "print(reward)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.squeeze(next_state),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-20.0,\n",
       " -18.0,\n",
       " -20.0,\n",
       " -22.0,\n",
       " -22.0,\n",
       " -20.0,\n",
       " -23.0,\n",
       " -23.0,\n",
       " -20.0,\n",
       " -23.0,\n",
       " -24.0,\n",
       " -23.0,\n",
       " -20.0,\n",
       " -17.0,\n",
       " -21.0,\n",
       " -19.0,\n",
       " -19.0,\n",
       " -15.0,\n",
       " -19.0,\n",
       " -18.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE GRAVEYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAMBDA = 0.075\n",
    "MIN_EPSILON = 0.01\n",
    "MAX_EPSILON = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_explore_game = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9901\n",
      "0.9802\n",
      "0.9703\n",
      "0.9604\n",
      "0.9505\n",
      "0.9406\n",
      "0.9307\n",
      "0.9208000000000001\n",
      "0.9109\n",
      "0.901\n",
      "0.8911\n",
      "0.8812\n",
      "0.8713\n",
      "0.8613999999999999\n",
      "0.8515\n",
      "0.8416\n",
      "0.8317\n",
      "0.8218000000000001\n",
      "0.8119000000000001\n",
      "0.802\n",
      "0.7921\n",
      "0.7822\n",
      "0.7723\n",
      "0.7624\n",
      "0.7525000000000001\n",
      "0.7426\n",
      "0.7327\n",
      "0.7228\n",
      "0.7129000000000001\n",
      "0.7030000000000001\n",
      "0.6931\n",
      "0.6832\n",
      "0.6733\n",
      "0.6634\n",
      "0.6535\n",
      "0.6436000000000001\n",
      "0.6337\n",
      "0.6238\n",
      "0.6139000000000001\n",
      "0.6040000000000001\n",
      "0.5941000000000001\n",
      "0.5842\n",
      "0.5743\n",
      "0.5644\n",
      "0.5545\n",
      "0.5446\n",
      "0.5347000000000001\n",
      "0.5248\n",
      "0.5149\n",
      "0.5050000000000001\n",
      "0.4951000000000001\n",
      "0.4852000000000001\n",
      "0.47530000000000006\n",
      "0.46540000000000004\n",
      "0.4555\n",
      "0.4456\n",
      "0.4357000000000001\n",
      "0.42580000000000007\n",
      "0.41590000000000005\n",
      "0.406\n",
      "0.3961\n",
      "0.3862000000000001\n",
      "0.3763000000000001\n",
      "0.36640000000000006\n",
      "0.35650000000000004\n",
      "0.3466\n",
      "0.3367000000000001\n",
      "0.3268000000000001\n",
      "0.31690000000000007\n",
      "0.30700000000000005\n",
      "0.29710000000000003\n",
      "0.2872000000000001\n",
      "0.2773000000000001\n",
      "0.2674000000000001\n",
      "0.25750000000000006\n",
      "0.24760000000000004\n",
      "0.23770000000000002\n",
      "0.2278000000000001\n",
      "0.2179000000000001\n",
      "0.20800000000000007\n",
      "0.19810000000000005\n",
      "0.18820000000000003\n",
      "0.17830000000000013\n",
      "0.1684000000000001\n",
      "0.15850000000000009\n",
      "0.14860000000000007\n",
      "0.13870000000000005\n",
      "0.12880000000000003\n",
      "0.11890000000000012\n",
      "0.1090000000000001\n",
      "0.09910000000000008\n",
      "0.08920000000000006\n",
      "0.07930000000000004\n",
      "0.06940000000000013\n",
      "0.05950000000000011\n",
      "0.04960000000000009\n",
      "0.03970000000000007\n",
      "0.02980000000000005\n",
      "0.01990000000000014\n",
      "0.01000000000000012\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "#     print(MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) \n",
    "#                         * math.exp(-LAMBDA * i))\n",
    "    if i <= min_explore_game:\n",
    "        print( ((MIN_EPSILON-MAX_EPSILON)/min_explore_game)*i + MAX_EPSILON)\n",
    "    else:\n",
    "        print(MIN_EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_game(num_steps):\n",
    "    state = ski_env_w.reset()\n",
    "    state_list = [state]\n",
    "    reward_list = []\n",
    "    for time_step in range(num_steps):\n",
    "        action = skiier.act(state)\n",
    "        next_state, reward, done, info = ski_env_w.step(action)\n",
    "        skiier.observe(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        state_list.append(state)\n",
    "        reward_list.append(reward)\n",
    "        skiier.episode = episode\n",
    "        if done:\n",
    "            break\n",
    "    return state_list, reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_out, rewards_out = play_game(num_steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"models/test_run.hdf5\"\n",
    "skiier.brain.model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00909090909090909\n",
      "0.008264462809917354\n",
      "0.007513148009015776\n",
      "0.006830134553650705\n",
      "0.00620921323059155\n",
      "0.005644739300537773\n",
      "0.005131581182307066\n",
      "0.004665073802097333\n",
      "0.0042409761837248474\n",
      "0.0038554328942953155\n",
      "0.003504938994813923\n",
      "0.0031863081771035663\n",
      "0.002896643797366878\n",
      "0.0026333125430607982\n",
      "0.002393920493691635\n",
      "0.002176291357901486\n",
      "0.001978446689001351\n",
      "0.001798587899092137\n",
      "0.001635079908265579\n",
      "0.0014864362802414354\n",
      "0.0013513057093103957\n",
      "0.0012284597357367234\n",
      "0.0011167815779424758\n",
      "0.0010152559799477053\n",
      "0.0009229599817706411\n",
      "0.000839054528882401\n",
      "0.0007627768444385463\n",
      "0.0006934334949441329\n",
      "0.0006303940863128481\n",
      "0.00057308553301168\n",
      "0.0005209868481924364\n",
      "0.0004736244074476694\n",
      "0.00043056764313424494\n",
      "0.00039142513012204084\n",
      "0.0003558410273836735\n",
      "0.0003234918430760668\n",
      "0.0002940834937055152\n",
      "0.00026734863064137743\n",
      "0.00024304420967397947\n",
      "0.0002209492815217995\n",
      "0.0002008629832016359\n",
      "0.0001826027120014872\n",
      "0.00016600246545589746\n",
      "0.00015091133223263406\n",
      "0.0001371921202114855\n",
      "0.00012472010928316863\n",
      "0.0001133819175301533\n",
      "0.00010307447048195755\n",
      "9.370406407450686e-05\n",
      "8.518551279500624e-05\n",
      "7.744137526818749e-05\n",
      "7.04012502438068e-05\n",
      "6.400113658527891e-05\n",
      "5.8182851441162644e-05\n",
      "5.2893501310147856e-05\n",
      "4.8085001191043505e-05\n",
      "4.3713637446403184e-05\n",
      "3.9739670405821074e-05\n",
      "3.6126973096200975e-05\n",
      "3.2842702814728156e-05\n",
      "2.9857002558843778e-05\n",
      "2.714272959894889e-05\n",
      "2.467520872631717e-05\n",
      "2.243200793301561e-05\n",
      "2.0392734484559646e-05\n",
      "1.853884953141786e-05\n",
      "1.6853499574016235e-05\n",
      "1.532136324910567e-05\n",
      "1.3928512044641516e-05\n",
      "1.2662283676946833e-05\n",
      "1.1511166979042576e-05\n",
      "1.0464697253675068e-05\n",
      "9.513361139704608e-06\n",
      "8.648510127004189e-06\n",
      "7.862281933640171e-06\n",
      "7.147529030581974e-06\n",
      "6.49775366416543e-06\n",
      "5.907048785604936e-06\n",
      "5.370044350549942e-06\n",
      "4.881858500499946e-06\n",
      "4.438053182272678e-06\n",
      "4.034593802066071e-06\n",
      "3.6678125473327914e-06\n",
      "3.33437504302981e-06\n",
      "3.031250039118009e-06\n",
      "2.7556818537436444e-06\n",
      "2.5051653215851313e-06\n",
      "2.2774230196228464e-06\n",
      "2.0703845632934966e-06\n",
      "1.8821677848122696e-06\n",
      "1.7110616225566088e-06\n",
      "1.5555105659605534e-06\n",
      "1.414100514509594e-06\n",
      "1.285545922281449e-06\n",
      "1.1686781111649538e-06\n",
      "1.0624346465135943e-06\n",
      "9.658496786487221e-07\n",
      "8.780451624079292e-07\n",
      "7.982228749162993e-07\n",
      "7.256571590148175e-07\n"
     ]
    }
   ],
   "source": [
    "GAMMA = 0.9\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.01\n",
    "LAMBDA = 0.03\n",
    "NUM_GAMES = 100\n",
    "lr = 0.01\n",
    "for game_num in range(NUM_GAMES):\n",
    "    #epsilon = (MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) \n",
    "    #        * (1-math.exp(-LAMBDA * game_num)))\n",
    "    #lr *= (1 / (1+lr_decay * num_games))\n",
    "    #print(MAX_EPSILON - MIN_EPSILON)\n",
    "    #print(math.exp(-LAMBDA * game_num))\n",
    "    #print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 10000\n",
    "num_episodes = 5 #converges around 30-45 with current hyper parameters\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = ski_env_w.reset()\n",
    "    total_reward = 0\n",
    "    for time_step in range(num_steps):\n",
    "        action = skiier.act(state)\n",
    "        #print(\"Action:\", action)\n",
    "        next_state, reward, done, info = ski_env_w.step(action)\n",
    "        if next_state.shape != (125, 80, 4):\n",
    "            print(next_state.shape)\n",
    "            break\n",
    "        if done:\n",
    "            print(done)\n",
    "            print(next_state.shape)\n",
    "            done = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#woo! test was successful\n",
    "\n",
    "- #checking to make sure score increases over time\n",
    "- #make updates to epsilon\n",
    "- #pull out memory as hyper parameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
